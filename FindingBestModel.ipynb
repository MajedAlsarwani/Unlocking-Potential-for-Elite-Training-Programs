{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Finding the best model:"
      ],
      "metadata": {
        "id": "Vv5VuCeVqyJB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1- Imports"
      ],
      "metadata": {
        "id": "UFq6j2sDrNV-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D3LyxUOgqv85"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2- Load and preprocess(Drop, Encode and scale) dataset"
      ],
      "metadata": {
        "id": "HCQEqU88rUlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"enriched_d_train.csv\")\n",
        "\n",
        "# Drop unused columns\n",
        "df = df.drop(columns=[\n",
        "    'Program Start Date', 'Program End Date',\n",
        "    'Technology Type', 'Education Speaciality', 'University Degree Score System',\n",
        "    'Job Type', 'Still Working', 'College', 'University Degree Score'\n",
        "], errors='ignore')\n",
        "\n",
        "\n",
        "# Encode categorical variables\n",
        "for col in df.select_dtypes(include='object').columns:\n",
        "    df[col] = LabelEncoder().fit_transform(df[col])\n",
        "\n",
        "# Split features and target\n",
        "X = df.drop(columns='Y')\n",
        "y = df['Y']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, stratify=y, random_state=42)\n",
        "\n",
        "# Scale numeric features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Q5zhh92Arf0A"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3- Define models\n",
        "\n",
        "LogisricRegression, RandomForest, XGBoost, KNN, SVM"
      ],
      "metadata": {
        "id": "oyEJSQfesC9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define models and hyperparameter grids\n",
        "models = {\n",
        "    'LogisticRegression': (LogisticRegression(max_iter=1000), {\n",
        "        'C': [0.1, 1, 10]\n",
        "    }),\n",
        "    'RandomForest': (RandomForestClassifier(), {\n",
        "        'n_estimators': [100, 200],\n",
        "        'max_depth': [None, 5]\n",
        "    }),\n",
        "    'XGBoost': (XGBClassifier(eval_metric='logloss'), {\n",
        "        'n_estimators': [100, 200],\n",
        "        'max_depth': [3, 5],\n",
        "        'learning_rate': [0.05, 0.1]\n",
        "    }),\n",
        "    'KNN': (KNeighborsClassifier(), {\n",
        "        'n_neighbors': [3, 5, 7]\n",
        "    }),\n",
        "    'SVM': (SVC(probability=True), {\n",
        "        'C': [0.1, 1],\n",
        "        'kernel': ['linear', 'rbf']\n",
        "    })\n",
        "}"
      ],
      "metadata": {
        "id": "riuvgbLjsg8t"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4- GridSearch for every model using for loop and evaluate"
      ],
      "metadata": {
        "id": "UEdk4CRyskhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through models and perform GridSearchCV\n",
        "for name, (model, params) in models.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    grid = GridSearchCV(model, params, cv=5, scoring='f1', n_jobs=-1)\n",
        "    grid.fit(X_train, y_train)\n",
        "\n",
        "    # Predict and evaluate\n",
        "    y_pred = grid.best_estimator_.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"Best Params: {grid.best_params_}\")\n",
        "    print(f\"Accuracy: {acc:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbERSntRst3e",
        "outputId": "336985b9-1811-4ebf-db31-1a7524ee85b8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training LogisticRegression...\n",
            "Best Params: {'C': 10}\n",
            "Accuracy: 0.8667\n",
            "F1 Score: 0.5390\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.94      0.92       819\n",
            "           1       0.60      0.49      0.54       156\n",
            "\n",
            "    accuracy                           0.87       975\n",
            "   macro avg       0.75      0.71      0.73       975\n",
            "weighted avg       0.86      0.87      0.86       975\n",
            "\n",
            "\n",
            "Training RandomForest...\n",
            "Best Params: {'max_depth': None, 'n_estimators': 100}\n",
            "Accuracy: 0.8985\n",
            "F1 Score: 0.6452\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.96      0.94       819\n",
            "           1       0.73      0.58      0.65       156\n",
            "\n",
            "    accuracy                           0.90       975\n",
            "   macro avg       0.83      0.77      0.79       975\n",
            "weighted avg       0.89      0.90      0.89       975\n",
            "\n",
            "\n",
            "Training XGBoost...\n",
            "Best Params: {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100}\n",
            "Accuracy: 0.8933\n",
            "F1 Score: 0.6463\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.95      0.94       819\n",
            "           1       0.69      0.61      0.65       156\n",
            "\n",
            "    accuracy                           0.89       975\n",
            "   macro avg       0.81      0.78      0.79       975\n",
            "weighted avg       0.89      0.89      0.89       975\n",
            "\n",
            "\n",
            "Training KNN...\n",
            "Best Params: {'n_neighbors': 7}\n",
            "Accuracy: 0.8759\n",
            "F1 Score: 0.5364\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.96      0.93       819\n",
            "           1       0.67      0.45      0.54       156\n",
            "\n",
            "    accuracy                           0.88       975\n",
            "   macro avg       0.78      0.70      0.73       975\n",
            "weighted avg       0.86      0.88      0.87       975\n",
            "\n",
            "\n",
            "Training SVM...\n",
            "Best Params: {'C': 0.1, 'kernel': 'linear'}\n",
            "Accuracy: 0.8605\n",
            "F1 Score: 0.6222\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.89      0.91       819\n",
            "           1       0.55      0.72      0.62       156\n",
            "\n",
            "    accuracy                           0.86       975\n",
            "   macro avg       0.75      0.80      0.77       975\n",
            "weighted avg       0.88      0.86      0.87       975\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Since XGBoost got the best combined results for Accuracy(89) and F1(65) we will be starting with it"
      ],
      "metadata": {
        "id": "AKAl5HhEtRJq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1-Enhancing XGBoost with GridSearch then constructing a pipeline with oversampling using SMOTE"
      ],
      "metadata": {
        "id": "GD7nuzjgtqys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Define best XGBoost model after GridSearch and manual tuning (locally)\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=500,\n",
        "    max_depth=3,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.7,\n",
        "    colsample_bytree=0.6,\n",
        "    min_child_weight=12.6,\n",
        "    gamma=0,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Pipeline: Scaling + SMOTE + XGBoost\n",
        "pipeline = ImbPipeline([\n",
        "    ('scaler', StandardScaler()), #Scaling now in pipeline instead of before so we can export it(No double scale!)\n",
        "    ('smote', SMOTE(random_state=42)),\n",
        "    ('clf', xgb_model)\n",
        "])\n",
        "\n",
        "# Train model\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9-nHhq4t16w",
        "outputId": "1a5f453b-039c-47b1-8d90-337c6dde591d"
      },
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9087\n",
            "F1 Score: 0.7063\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.95      0.95       819\n",
            "           1       0.73      0.69      0.71       156\n",
            "\n",
            "    accuracy                           0.91       975\n",
            "   macro avg       0.83      0.82      0.83       975\n",
            "weighted avg       0.91      0.91      0.91       975\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2- Add Threshold tuning\n"
      ],
      "metadata": {
        "id": "X1d8XPu-_WSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_probs = pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "thresholds = np.arange(0.3, 0.71, 0.01)\n",
        "f1_scores = [f1_score(y_test, y_probs > t) for t in thresholds]\n",
        "best_thresh = thresholds[np.argmax(f1_scores)]\n",
        "\n",
        "print(f\"\\nBest Threshold: {best_thresh:.2f}\")\n",
        "print(f\"Max F1 Score: {max(f1_scores):.4f}\")\n",
        "\n",
        "# Predict with best threshold\n",
        "y_pred = (y_probs > best_thresh).astype(int)\n",
        "\n",
        "# === Evaluation ===\n",
        "print(\"\\nFinal Evaluation on Test Set:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rz5imRzN6fey",
        "outputId": "2d0e1e64-46df-4e7a-a01a-104487fe4127"
      },
      "execution_count": 320,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Threshold: 0.47\n",
            "Max F1 Score: 0.7284\n",
            "\n",
            "Final Evaluation on Test Set:\n",
            "Accuracy: 0.9128\n",
            "F1 Score: 0.7284\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.95      0.95       819\n",
            "           1       0.73      0.73      0.73       156\n",
            "\n",
            "    accuracy                           0.91       975\n",
            "   macro avg       0.84      0.84      0.84       975\n",
            "weighted avg       0.91      0.91      0.91       975\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exporting the pipeline"
      ],
      "metadata": {
        "id": "ElG_1LLZUjJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(pipeline,'final_model_pipeline.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQ8v-Sw4Uiub",
        "outputId": "3326fdf2-a344-4043-e589-e204d821cc7f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['final_model_pipeline.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}